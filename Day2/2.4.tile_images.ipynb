{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating DCNN training libraries from label images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Written by Dr Daniel Buscombe, Northern Arizona University\n",
    "\n",
    "> Part of a series of notebooks for image recognition and classification using deep convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to demonstrate how to create libraries of categorized image tiles from ground truth (labelled) images, in order to retrain a DCNN using transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image is divided up into tiles of a specified size, \"tilesize\". \n",
    "\n",
    "If the proportion of pixels within the tile is greater than a specified amount, \"threshold\", then the tile is written to a file in a folder denoting its class. \n",
    "\n",
    "The tiles can then be 'thinned', by specifying what proportion of tiles (randomly selected from the entire catalogue) to keep - \"prop_keep\"\n",
    "\n",
    "This generates both ground-truth label imagery (to evaluate classification performance) and sets of data suitable for training a DCNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a local directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are from the California Coastal Records Project\n",
    "\n",
    "Copyright (C) 2002â€“2018 Kenneth and Gabrielle Adelman, www.Californiacoastline.org and are used with permission. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's take a look at how many test/train images we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "files = glob('ccr_train/*.JPG')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30 training images. How many test images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob('ccr_test/*.JPG')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have 19 training images\n",
    "\n",
    "Ok, let's create some 224x224 pixel tiles from the training images. We'll only keep tiles with 90% or more of pixels representing the dominant class, then we'll randomly select 10% of those tiles to train with (to speed things up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "direc='ccr_train'\n",
    "tilesize = 224\n",
    "threshold = 0.9\n",
    "prop_keep=0.125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retiling takes a few minutes, so let's watch a video on one convolutional net layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "## CNN example\n",
    "YouTubeVideo('bXJx7y51cl0') ##11 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## approx 6 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccr_train/201300025.JPG\n",
      "ccr_train/201301034.JPG\n",
      "ccr_train/201301088.JPG\n",
      "ccr_train/201301127.JPG\n",
      "ccr_train/201302268.JPG\n",
      "ccr_train/201302501.JPG\n",
      "ccr_train/201302679.JPG\n",
      "ccr_train/201302765.JPG\n",
      "ccr_train/201303369.JPG\n",
      "ccr_train/201303464.JPG\n",
      "ccr_train/201303950.JPG\n",
      "ccr_train/201304247.JPG\n",
      "ccr_train/201304817.JPG\n",
      "ccr_train/201305224.JPG\n",
      "ccr_train/201305496.JPG\n",
      "ccr_train/201305596.JPG\n",
      "ccr_train/201305657.JPG\n",
      "ccr_train/201305721.JPG\n",
      "ccr_train/201305944.JPG\n",
      "ccr_train/201306308.JPG\n",
      "ccr_train/201306532.JPG\n",
      "ccr_train/201306933.JPG\n",
      "ccr_train/201307292.JPG\n",
      "ccr_train/201308459.JPG\n",
      "ccr_train/201308874.JPG\n",
      "ccr_train/201309043.JPG\n",
      "ccr_train/201309819.JPG\n",
      "ccr_train/201309922.JPG\n",
      "ccr_train/201310389.JPG\n",
      "ccr_train/201310440.JPG\n",
      "thinning files ...\n",
      "beach: 257\n",
      "buildings: 322\n",
      "cliff: 752\n",
      "road: 1264\n",
      "sky: 1487\n",
      "surf: 2343\n",
      "swash: 95\n",
      "terrain: 568\n",
      "veg: 64\n",
      "water: 429\n"
     ]
    }
   ],
   "source": [
    "%run ./retile.py $direc $tilesize $threshold $prop_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the same on the 'test' directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "direc='ccr_test'\n",
    "tilesize = 224\n",
    "threshold = 0.9\n",
    "prop_keep=0.125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## approx 4 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccr_test/201301651.JPG\n",
      "ccr_test/201302661.JPG\n",
      "ccr_test/201302989.JPG\n",
      "ccr_test/201303838.JPG\n",
      "ccr_test/201304702.JPG\n",
      "ccr_test/201305404.JPG\n",
      "ccr_test/201305642.JPG\n",
      "ccr_test/201305789.JPG\n",
      "ccr_test/201306224.JPG\n",
      "ccr_test/201306768.JPG\n",
      "ccr_test/201306957.JPG\n",
      "ccr_test/201308103.JPG\n",
      "ccr_test/201308826.JPG\n",
      "ccr_test/201308902.JPG\n",
      "ccr_test/201309654.JPG\n",
      "ccr_test/201309844.JPG\n",
      "ccr_test/201310085.JPG\n",
      "ccr_test/201310435.JPG\n",
      "ccr_test/201310453.JPG\n",
      "thinning files ...\n",
      "beach: 218\n",
      "buildings: 600\n",
      "cliff: 427\n",
      "road: 640\n",
      "sky: 922\n",
      "surf: 817\n",
      "swash: 49\n",
      "terrain: 543\n",
      "veg: 10\n",
      "water: 386\n"
     ]
    }
   ],
   "source": [
    "%run ./retile.py $direc $tilesize $threshold $prop_keep "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdi-workshop/semseg_data/ontario/train\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "S3direc='cdi-workshop/semseg_data/ontario/train'\n",
    "print(S3direc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f for f in fs.ls(S3direc) if f.endswith('.JPG')]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tilesize = 224\n",
    "threshold = 0.9\n",
    "prop_keep=0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The s3 bucket is a read-only filesystem, which means we have to write out the tiles here to your local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "## Why convolutions?\n",
    "YouTubeVideo('ay3zYUeuyhU') ##9 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdi-workshop/semseg_data/ontario/train\n",
      "0\n",
      "cdi-workshop/semseg_data/ontario/train/A2013170_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2013473_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2013540_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2013594_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2013649_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2013657_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2013671_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2013697_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2013709_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2013733_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2013743_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2013773_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2013900_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2013960_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2014128_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2014153_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2014155_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2014158_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2014160_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2014162_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2014164_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2014166_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2014168_geotag.JPG\n",
      "cdi-workshop/semseg_data/ontario/train/A2014858_geotag.JPG\n",
      "thinning files ...\n",
      "sediment: 72\n",
      "terrain: 39\n",
      "water: 3333\n",
      "veg: 1284\n",
      "anthro: 54\n"
     ]
    }
   ],
   "source": [
    "%run ./retile_fromS3.py $S3direc $tilesize $threshold $prop_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to retrain the DCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equivalent function in DL-tools is called using:\n",
    "\n",
    "```python create_library\\retile.py -t 96 -a 0.9 -b 0.5```\n",
    "\n",
    "where ```t``` is the tile size, ```a``` is the threshold proportion of pixels in a tile uniformly classified, and ```b``` is the proportion of the tiles to randomly select and keep\n",
    "\n",
    "You will be prompted to select a set of .mat files. The tiles will be created in folders called \"test\" and \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
